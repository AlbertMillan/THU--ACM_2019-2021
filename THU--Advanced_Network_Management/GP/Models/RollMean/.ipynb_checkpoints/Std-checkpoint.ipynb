{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_comp(cf):\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "    if (cf[0] + cf[2]) != 0:\n",
    "        prec = cf[0] / (cf[0] + cf[2])\n",
    "    if (cf[0] + cf[3]) != 0:\n",
    "        rec  = cf[0] / (cf[0] + cf[3])\n",
    "    if (prec + rec) != 0:\n",
    "        f1   = 2 * (prec * rec / (prec+rec))\n",
    "        \n",
    "    return f1, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(pred,truth):\n",
    "    res = [0,0,0,0]\n",
    "    a = 0\n",
    "    \n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == 1:\n",
    "            if truth[i] == pred[i]:\n",
    "                a = 0\n",
    "            else:\n",
    "                a = 2\n",
    "                \n",
    "        else:\n",
    "            if truth[i] == pred[i]:\n",
    "                a = 1\n",
    "            else:\n",
    "                a = 3\n",
    "                \n",
    "        res[a] = res[a] + 1\n",
    "     \n",
    "    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(r_mean,limit):\n",
    "    res = [0 for i in range(len(r_mean))]\n",
    "\n",
    "    for i in range(1,len(r_mean)):\n",
    "        if abs(r_mean[i] - r_mean[i-1]) > limit:\n",
    "            res[i-1] = 1\n",
    "            res[i] = 1\n",
    "            if i < (len(r_mean)-1):\n",
    "                res[i+1] = 1\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rolling(arr, kernel_a, kernel_b):\n",
    "    start = kernel_a + kernel_b\n",
    "    pred = np.zeros(len(arr))\n",
    "    pred_normal = np.zeros(len(arr))\n",
    "    \n",
    "    \n",
    "    for i in range(start,len(arr)):\n",
    "        a_sset = arr[(i-start):(i-kernel_b)]\n",
    "        b_sset = arr[(i-kernel_b):i]\n",
    "        \n",
    "        a_mu = np.mean(a_sset)\n",
    "        a_std = np.std(a_sset)\n",
    "        \n",
    "        b_mu = np.mean(b_sset)\n",
    "        b_std = np.std(b_sset)\n",
    "        \n",
    "#         print(a_sset)\n",
    "#         print(b_sset, i)\n",
    "#         print(abs(b_mu-a_mu), 2 * abs(a_std))\n",
    "        if abs(b_mu-a_mu) >= 3 * abs(a_std):\n",
    "            pred[i] = 1\n",
    "            \n",
    "        # Normal Method\n",
    "#         b_sset = arr[(i-kernel_b):i]\n",
    "#         b_mu = np.mean(b_sset)\n",
    "#         b_std = np.std(b_sset)\n",
    "        \n",
    "        if arr[i] > (b_mu + 2 * b_std) or arr[i] < (b_mu - 2 * b_std):\n",
    "            pred_normal[i] = 1\n",
    "            \n",
    "            \n",
    "    return pred, pred_normal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = [i for i in range(20)]\n",
    "# compute_rolling(z,5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a40b1df87e3f1c87\n",
      "[176, 115267, 205, 22277]\n",
      "[162, 108665, 219, 28879]\n",
      "0.015415608303407198 0.011012167765617564\n",
      "b3b2e6d1a791d63a\n",
      "[4, 6951, 8, 1284]\n",
      "[2, 6589, 10, 1646]\n",
      "0.006153846153846153 0.0024096385542168672\n",
      "da403e4e3f87c9e0\n",
      "[6835, 97721, 831, 23648]\n",
      "[648, 103345, 7018, 18024]\n",
      "0.3583318042412645 0.04920646973953983\n",
      "046ec29ddf80d62e\n",
      "[58, 6007, 22, 2697]\n",
      "[11, 6929, 69, 1775]\n",
      "0.04091710758377425 0.011789924973204717\n",
      "18fbb1d5a5dc099d\n",
      "[774, 113925, 7089, 7340]\n",
      "[1439, 99471, 6424, 21794]\n",
      "0.09688927833761032 0.09255209673269874\n",
      "09513ae3e75778a3\n",
      "[56, 116998, 182, 11735]\n",
      "[61, 107738, 177, 20995]\n",
      "0.00931083215562391 0.005729313421621114\n",
      "07927a9a18fa19ae\n",
      "[84, 866, 46, 9964]\n",
      "[43, 4018, 87, 6812]\n",
      "0.016506189821182942 0.01231209735146743\n",
      "cff6d3c01e6a6bfa\n",
      "[285, 127928, 802, 18614]\n",
      "[303, 116809, 784, 29733]\n",
      "0.028519963974782344 0.01947113067506346\n",
      "54e8a140f6237526\n",
      "[1, 6614, 3, 1630]\n",
      "[2, 6441, 2, 1803]\n",
      "0.0012232415902140672 0.0022111663902708682\n",
      "c58bfcbacb2822d1\n",
      "[79, 47194, 45, 81349]\n",
      "[53, 79928, 71, 48615]\n",
      "0.001937414165195213 0.002172487292998852\n",
      "7c189dd36f048a6c\n",
      "[172, 124008, 254, 23255]\n",
      "[150, 116428, 276, 30835]\n",
      "0.014421666037814949 0.009550794307726592\n",
      "8bef9af9a922e0b3\n",
      "[187, 108508, 340, 20418]\n",
      "[171, 102024, 356, 26902]\n",
      "0.017698277493848193 0.012391304347826086\n",
      "40e25005ff8992bd\n",
      "[182, 88157, 472, 11443]\n",
      "[201, 79537, 453, 20063]\n",
      "0.02964410782637022 0.019217898460655893\n",
      "76f4550c43334374\n",
      "[19, 5796, 68, 2901]\n",
      "[18, 6518, 69, 2179]\n",
      "0.012637179913535086 0.01576182136602452\n",
      "affb01ca2b4f0b45\n",
      "[216, 124030, 368, 23066]\n",
      "[201, 116293, 383, 30803]\n",
      "0.018101064275538425 0.012726351779156642\n",
      "88cf3a776ba00e7c\n",
      "[1018, 24875, 2088, 37455]\n",
      "[827, 40535, 2279, 21795]\n",
      "0.04896702662401693 0.06428793532338309\n",
      "9bd90500bfd11edb\n",
      "[49, 95921, 94, 32549]\n",
      "[40, 96646, 103, 31824]\n",
      "0.002993188967960661 0.0024994532446027426\n",
      "e0770391decc44ce\n",
      "[448, 112731, 2626, 31219]\n",
      "[647, 112363, 2427, 31587]\n",
      "0.025790852307072332 0.03664891809221706\n",
      "8a20c229e9860d0c\n",
      "[2, 4533, 2, 4247]\n",
      "[2, 6244, 2, 2536]\n",
      "0.0009405125793557487 0.0015735641227380016\n",
      "769894baefea4e9e\n",
      "[3, 4217, 6, 4558]\n",
      "[2, 6158, 7, 2617]\n",
      "0.001312910284463895 0.0015220700152207\n",
      "1c35dbf57f55f5e4\n",
      "[839, 109069, 8742, 10203]\n",
      "[1875, 96811, 7706, 22461]\n",
      "0.08136546574213258 0.11056402394079665\n",
      "9ee5879409dccef9\n",
      "[1418, 19895, 1527, 42609]\n",
      "[936, 37645, 2009, 24859]\n",
      "0.06037639444775612 0.0651356993736952\n",
      "71595dd7171f4540\n",
      "[326, 127912, 787, 18643]\n",
      "[306, 116569, 807, 29986]\n",
      "0.032466885768349774 0.019487342779812133\n",
      "8c892e5525f3e491\n",
      "[478, 113517, 2605, 30409]\n",
      "[657, 112811, 2426, 31115]\n",
      "0.02814247865763909 0.03769903887534069\n",
      "a5bf5d65261d859a\n",
      "[24, 15162, 5, 113488]\n",
      "[8, 125617, 21, 3033]\n",
      "0.0004227547758078579 0.005211726384364821\n",
      "02e99bd4f6cfb33f\n",
      "[2701, 94566, 7849, 23446]\n",
      "[2429, 93279, 8121, 24733]\n",
      "0.14720549363708202 0.1288184132371659\n"
     ]
    }
   ],
   "source": [
    "input_dir = './../../train/KPI/'\n",
    "\n",
    "summary = pd.DataFrame(columns=['KPI', 'TP', 'TN', 'FP', 'FN', 'PRECISION', 'RECALL', 'F1_SCORE'])\n",
    "summary_2 = pd.DataFrame(columns=['KPI', 'TP', 'TN', 'FP', 'FN', 'PRECISION', 'RECALL', 'F1_SCORE'])\n",
    "\n",
    "for fname in os.listdir(input_dir):\n",
    "    df  = pd.read_csv(os.path.join(input_dir, fname), index_col='timestamp')\n",
    "    kpi_name = df['KPI ID'].values[0]\n",
    "    print(kpi_name)\n",
    "    df = df.drop(['KPI ID'], axis=1)\n",
    "\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred, y_normal_pred = compute_rolling(df.value.values,5,5)\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    cf = conf_mat(y_pred,df.label.values)\n",
    "    cf_2 = conf_mat(y_normal_pred,df.label.values)\n",
    "\n",
    "    # F1-Score\n",
    "    f1, prec, rec = f1_comp(cf)\n",
    "    f1_2, prec_2, rec_2 = f1_comp(cf_2)\n",
    "\n",
    "    print(f1,f1_2)\n",
    "\n",
    "    summary = summary.append({'KPI': kpi_name, \n",
    "                                   'TP': cf[0],  \n",
    "                                   'TN': cf[1], \n",
    "                                   'FP': cf[2], \n",
    "                                   'FN': cf[3], \n",
    "                                   'PRECISION': prec, \n",
    "                                   'RECALL': rec,     \n",
    "                                   'F1_SCORE': f1 }, ignore_index=True)\n",
    "    \n",
    "    summary_2 = summary_2.append({'KPI': kpi_name, \n",
    "                                   'TP': cf_2[0],  \n",
    "                                   'TN': cf_2[1], \n",
    "                                   'FP': cf_2[2], \n",
    "                                   'FN': cf_2[3], \n",
    "                                   'PRECISION': prec_2, \n",
    "                                   'RECALL': rec_2,     \n",
    "                                   'F1_SCORE': f1_2 }, ignore_index=True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_2.to_csv('Rolling_Mean_5_set.csv')\n",
    "\n",
    "summary_2.to_csv('Rolling_Mean_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9ee5879409dccef9\n",
      "[1418, 19895, 1527, 42609]\n",
      "[936, 37645, 2009, 24859]\n",
      "0.06037639444775612\n"
     ]
    }
   ],
   "source": [
    "input_dir = './../../train/KPI/'\n",
    "fname = 'train_9ee5879409dccef9.csv'\n",
    "\n",
    "summary = pd.DataFrame(columns=['KPI', 'TP', 'TN', 'FP', 'FN', 'PRECISION', 'RECALL', 'F1_SCORE'])\n",
    "\n",
    "df  = pd.read_csv(os.path.join(input_dir, fname), index_col='timestamp')\n",
    "kpi_name = df['KPI ID'].values[0]\n",
    "print(kpi_name)\n",
    "df = df.drop(['KPI ID'], axis=1)\n",
    "\n",
    "\n",
    "# Make Predictions\n",
    "y_pred, y_normal_pred = compute_rolling(df.value.values,5,5)\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "cf = conf_mat(y_pred,df.label.values)\n",
    "cf_2 = conf_mat(y_normal_pred,df.label.values)\n",
    "\n",
    "# F1-Score\n",
    "f1, prec, rec = f1_comp(cf)\n",
    "f1_2, prec_2, rec_2 = f1_comp(cf_2)\n",
    "\n",
    "print(f1,f1_2)\n",
    "\n",
    "summary = summary.append({'KPI': kpi_name, \n",
    "                               'TP': cf[0],  \n",
    "                               'TN': cf[1], \n",
    "                               'FP': cf[2], \n",
    "                               'FN': cf[3], \n",
    "                               'PRECISION': prec, \n",
    "                               'RECALL': rec,     \n",
    "                               'F1_SCORE': f1 }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_normal_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
