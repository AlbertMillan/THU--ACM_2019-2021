{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(pred,truth):\n",
    "    res = [0,0,0,0]\n",
    "    a = 0\n",
    "    \n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == 1:\n",
    "            if truth[i] == pred[i]:\n",
    "                a = 0\n",
    "            else:\n",
    "                a = 2\n",
    "                \n",
    "        else:\n",
    "            if truth[i] == pred[i]:\n",
    "                a = 1\n",
    "            else:\n",
    "                a = 3\n",
    "                \n",
    "        res[a] = res[a] + 1\n",
    "     \n",
    "    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-dataset Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a40b1df87e3f1c87\n",
      "[0, 34376, 106, 0]\n",
      "b3b2e6d1a791d63a\n",
      "[0, 2062, 0, 0]\n",
      "da403e4e3f87c9e0\n",
      "[123, 31997, 139, 0]\n",
      "046ec29ddf80d62e\n",
      "[0, 2196, 0, 0]\n",
      "18fbb1d5a5dc099d\n",
      "[15, 32170, 36, 61]\n",
      "09513ae3e75778a3\n",
      "[0, 32115, 128, 0]\n",
      "07927a9a18fa19ae\n",
      "[7, 2716, 17, 0]\n",
      "cff6d3c01e6a6bfa\n",
      "[0, 36619, 289, 0]\n",
      "54e8a140f6237526\n",
      "[0, 2062, 0, 0]\n",
      "c58bfcbacb2822d1\n",
      "[0, 32120, 47, 0]\n",
      "7c189dd36f048a6c\n",
      "[0, 36843, 80, 0]\n",
      "8bef9af9a922e0b3\n",
      "[0, 32288, 76, 0]\n",
      "40e25005ff8992bd\n",
      "[0, 24904, 160, 0]\n",
      "76f4550c43334374\n",
      "[0, 2192, 4, 0]\n",
      "affb01ca2b4f0b45\n",
      "[14, 36809, 79, 18]\n",
      "88cf3a776ba00e7c\n",
      "[0, 15548, 811, 0]\n",
      "9bd90500bfd11edb\n",
      "[0, 32154, 0, 0]\n",
      "e0770391decc44ce\n",
      "[0, 34050, 2706, 0]\n",
      "8a20c229e9860d0c\n",
      "769894baefea4e9e\n",
      "[0, 2190, 6, 0]\n",
      "1c35dbf57f55f5e4\n",
      "[2687, 28507, 25, 995]\n",
      "9ee5879409dccef9\n",
      "[0, 15581, 782, 0]\n",
      "71595dd7171f4540\n",
      "[0, 36640, 277, 0]\n",
      "8c892e5525f3e491\n",
      "[0, 34067, 2686, 0]\n",
      "a5bf5d65261d859a\n",
      "[0, 32160, 10, 0]\n",
      "02e99bd4f6cfb33f\n",
      "[731, 30558, 651, 201]\n"
     ]
    }
   ],
   "source": [
    "input_dir = './../../train/KPI'\n",
    "\n",
    "summary = pd.DataFrame(columns=['KPI', 'TP', 'TN', 'FP', 'FN', 'PRECISION', 'RECALL', 'F1_SCORE'])\n",
    "\n",
    "for fname in os.listdir(input_dir):\n",
    "    df  = pd.read_csv(os.path.join(input_dir, fname), index_col='timestamp')\n",
    "    kpi_name = df['KPI ID'].values[0]\n",
    "    print(kpi_name)\n",
    "    df = df.drop(['KPI ID'], axis=1)\n",
    "    \n",
    "    # Normalize Values\n",
    "    normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "    normalized_df = normalized_df.astype({'label': 'int64'})\n",
    "    \n",
    "    # Split to Train and Test\n",
    "    train_set, test_set= np.split(normalized_df, [int(.75 *len(normalized_df))])\n",
    "    \n",
    "    # Format Train and Test\n",
    "    X = np.array(train_set['value']).reshape(-1, 1)\n",
    "    y = np.array(train_set['label'])\n",
    "    x_test = np.array(test_set['value']).reshape(-1,1)\n",
    "    y_test = np.array(test_set['label'])\n",
    "    \n",
    "    \n",
    "    # Check Valid Train Dataset\n",
    "    if len(np.unique(y)) > 1:\n",
    "\n",
    "        # Train Model\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                              hidden_layer_sizes=(20,2), random_state=1)\n",
    "        model.fit(X,y)\n",
    "\n",
    "        # Make Predictions\n",
    "        predictions = model.predict(x_test)\n",
    "\n",
    "        # Compute Confusion Matrix\n",
    "        cf = conf_mat(predictions,y_test) \n",
    "\n",
    "        # F1-Score\n",
    "        prec = 0\n",
    "        rec = 0\n",
    "        f1 = 0\n",
    "        if (cf[0] + cf[2]) != 0:\n",
    "            prec = cf[0] / (cf[0] + cf[2])\n",
    "        if (cf[0] + cf[3]) != 0:\n",
    "            rec  = cf[0] / (cf[0] + cf[3])\n",
    "        if (prec + rec) != 0:\n",
    "            f1   = 2 * (prec * rec / (prec+rec))\n",
    "\n",
    "    #     print(f1_score(predictions,y_test))\n",
    "\n",
    "\n",
    "        summary = summary.append({'KPI': kpi_name, \n",
    "                                   'TP': cf[0],  \n",
    "                                   'TN': cf[1], \n",
    "                                   'FP': cf[2], \n",
    "                                   'FN': cf[3], \n",
    "                                   'PRECISION': prec, \n",
    "                                   'RECALL': rec,     \n",
    "                                   'F1_SCORE': f1 }, ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        summary = summary.append({'KPI': kpi_name, \n",
    "                                   'TP': None,  \n",
    "                                   'TN': None, \n",
    "                                   'FP': None, \n",
    "                                   'FN': None, \n",
    "                                   'PRECISION': None, \n",
    "                                   'RECALL': None,     \n",
    "                                   'F1_SCORE': None }, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('MLP_Result1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
